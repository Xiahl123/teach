1.安装构建c++的必要程序
sudo apt update
sudo apt install build-essential
sudo apt install build-essential cmake git pkg-config libgtk2.0-dev libavcodec-dev libavformat-dev libswscale-dev libv4l-dev libxvidcore-dev libx264-dev libatlas-base-dev gfortran libhdf5-dev libtiff-dev libpng-dev libjpeg-dev libopenexr-dev libtbb-dev python3-dev python3-numpy  libxine2-dev libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev
//无法安装的库
libjasper-dev libdc1394-22-dev

2.安装cuda驱动，toolkit,tensorRT,以ubuntu22.04,nvidia4060,使用cuda12.8为例子
2.1cuda驱动，需要安装开源版本
cuda驱动在software&update中的additional drivers查看驱动，安装metapackage 570版本，
也可使用安装开源版本：
sudo apt install nvidia-driver-570-open
卸载nvidia驱动：
sudo apt purge nvidia-*
sudo apt autoremove
2.2toolkit,需要使用nvidia-smi查看cuda驱动支持的最高版本，以确定下载版本
如有更改配置，查看：https://developer.nvidia.com/cuda-downloads
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-8
2.3安装tensorRT10.8,最高支持cuda12.8
强制安装10.8.0.43版本
sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/3bf863cc.pub
sudo add-apt-repository "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/ /"
sudo apt update

sudo apt install \
    tensorrt=10.8.0.43-1+cuda12.8 \
    libnvinfer10=10.8.0.43-1+cuda12.8 \
    libnvinfer-plugin10=10.8.0.43-1+cuda12.8 \
    libnvinfer-vc-plugin10=10.8.0.43-1+cuda12.8 \
    libnvinfer-lean10=10.8.0.43-1+cuda12.8 \
    libnvinfer-dispatch10=10.8.0.43-1+cuda12.8 \
    libnvonnxparsers10=10.8.0.43-1+cuda12.8 \
    libnvinfer-bin=10.8.0.43-1+cuda12.8 \
    libnvinfer-dev=10.8.0.43-1+cuda12.8 \
    libnvinfer-lean-dev=10.8.0.43-1+cuda12.8 \
    libnvinfer-plugin-dev=10.8.0.43-1+cuda12.8 \
    libnvinfer-vc-plugin-dev=10.8.0.43-1+cuda12.8 \
    libnvinfer-dispatch-dev=10.8.0.43-1+cuda12.8 \
    libnvonnxparsers-dev=10.8.0.43-1+cuda12.8 \
    libnvinfer-samples=10.8.0.43-1+cuda12.8 \
    python3-libnvinfer-dev=10.8.0.43-1+cuda12.8 \
    libnvinfer-headers-dev=10.8.0.43-1+cuda12.8 \
    libnvinfer-headers-plugin-dev=10.8.0.43-1+cuda12.8 \
    python3-libnvinfer=10.8.0.43-1+cuda12.8 \
    python3-libnvinfer-lean=10.8.0.43-1+cuda12.8 \
    python3-libnvinfer-dispatch=10.8.0.43-1+cuda12.8 \
    --allow-downgrades --fix-missing
3.安装opencv,编译cuda，30系列为8.6，40系列为8.9,5070:12.0
架构版本号查询：
nvidia-smi --query-gpu=compute_cap --format=csv

git clone https://github.com/opencv/opencv.git
git clone https://github.com/opencv/opencv_contrib.git
cd ~/opencv
mkdir build
cd build
cmake -D CMAKE_BUILD_TYPE=RELEASE \
      -D CMAKE_INSTALL_PREFIX=/usr/local \
      -D INSTALL_C_EXAMPLES=ON \
      -D INSTALL_PYTHON_EXAMPLES=ON \
      -D OPENCV_GENERATE_PKGCONFIG=ON \
      -D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib/modules \
      -D BUILD_EXAMPLES=ON \
      -D WITH_CUDA=ON \
      -D CUDA_ARCH_BIN=8.9 \
      -D CUDA_ARCH_PTX="" \
      -D WITH_CUDNN=OFF \
      -D OPENCV_DNN_CUDA=OFF \
      -D WITH_GTK=ON ..
make -j$(nproc)
sudo make install
//强制刷新动态库链接
sudo ldconfig
//构建配置文件
sudo nano /etc/ld.so.conf.d/opencv.conf
//添加以下内容：
/usr/local/lib
//最后运行
sudo ldconfig

3.安装qt5,建议为5.15.3
sudo apt install qtcreator
sudo apt install qtbase5-dev qtchooser qt5-qmake qtbase5-dev-tools
sudo apt-get install qtmultimedia5-dev
sudo apt-get install qtwebengine5-dev
4.安装ffmpeg
sudo apt install ffmpeg libavcodec-dev libavformat-dev libswscale-dev libavutil-dev libavdevice-dev
5.安装
boost,nlohmann_json,yaml,dlib,OpenSSL:安全通信,RandR:动态调整屏幕大小和旋转,Xinerama:支持多显示器
sudo apt install libboost-all-dev
sudo apt install nlohmann-json3-dev
//如果没有可安装的nlohmann，可以查找可用的版本：apt-cache search nlohmann json
sudo apt install libyaml-cpp-dev
sudo apt install libdlib-dev
sudo apt install libssl-dev
sudo apt install libxrandr-dev
sudo apt install libxinerama-dev
sudo apt install libblas-dev
sudo apt install liblapack-dev
sudo apt install libsqlite3-dev
6.安装realsense2:https://blog.csdn.net/m0_56182552/article/details/143685591
git clone -b v2.48.0 https://github.com/IntelRealSense/librealsense
cd librealsense
sudo apt-get install libudev-dev pkg-config libgtk-3-dev
sudo apt-get install libusb-1.0-0-dev pkg-config
sudo apt-get install libglfw3-dev
sudo apt-get install libssl-dev
mkdir build
cd build
cmake ../ -DCMAKE_BUILD_TYPE=Release -DBUILD_EXAMmakePLES=true
make -j8
sudo make install
7.安装miniconda,用于转换模型
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
chmod +x Miniconda3-latest-Linux-x86_64.sh
./Miniconda3-latest-Linux-x86_64.sh
source ~/.bashrc
//如果无法启动conda，执行下面的语句
~/miniconda3/bin/conda init bash
//配置转换模型所需环境
conda create -n tensorrt python=3.9
conda activate tensorrt
pip install -U tensorrt_yolo
pip install torch
pip install ultralytics
pip install onnx

//吊钩和人yolo11m.pt文件量化部署
trtyolo export -w <input_pt_path.pt> -v yolo11 -o <output_path> -b 1 -s --imgsz 736 --iou_thres=0.3 --conf_thres=0.3
<trtexec_path_usual_in_/usr/src/tensorrt/bin/trtexec> --onnx=<input_onnx_path.onnx> --saveEngine=<output_engine_path.engine> --fp16

//吊钩和人yolo12x.pt文件量化部署
trtyolo export -w <input_pt_path.pt> -v ultralytics -o <output_path> -b 1 -s --imgsz 736 --iou_thres=0.3 --conf_thres=0.3
<trtexec_path_usual_in_/usr/src/tensorrt/bin/trtexec> --onnx=<input_onnx_path.onnx> --saveEngine=<output_engine_path.engine> --fp16

//大型机械yolo11m-obb.pt文件量化部署
trtyolo export -w <input_pt_path.pt> -v yolo11 -o <output_path> -b 1 -s --iou_thres=0.3 --conf_thres=0.3
<trtexec_path_usual_in_/usr/src/tensorrt/bin/trtexec> --onnx=<input_onnx_path.onnx> --saveEngine=output_engine_path.engine> --fp16 --staticPlugins=$TensorRT-YOLO/lib/plugin/libcustom_plugins.so --setPluginsToSerialize=$TensorRT-YOLO/lib/plugin/libcustom_plugins.so



//东涌电脑
//yolo11m-p.pt -> yolo11m-p.onnx -> yolo11m-p.engine
trtyolo export -w /home/craner/Documents/remote_cockpit_cpu_exit_20250911/ai_detect/tensorrt/yolo11m-p.pt -v yolo11 -o /home/craner/Documents/remote_cockpit_cpu_exit_20250911/ai_detect/tensorrt/ -b 1 -s --imgsz 736 --iou_thres=0.3 --conf_thres=0.3
/usr/src/tensorrt/bin/trtexec --onnx=/home/craner/Documents/remote_cockpit_cpu_exit_20250911/ai_detect/tensorrt/yolo11m-p.onnx --saveEngine=/home/craner/Documents/remote_cockpit_cpu_exit_20250911/ai_detect/tensorrt/yolo11m-p.engine --fp16


//yolo12x-v1.4-nov-300.pt -> yolo12x-v1.4-nov-300.onnx -> yolo12x-v1.4-nov-300.engine
trtyolo export -w /home/craner/Documents/remote_cockpit_cpu_exit_20250911/ai_detect/tensorrt/yolo12x-v1.4-nov-300.pt -v ultralytics -o /home/craner/Documents/remote_cockpit_cpu_exit_20250911/ai_detect/tensorrt/ -b 1 -s --imgsz 736 --iou_thres=0.3 --conf_thres=0.3
/usr/src/tensorrt/bin/trtexec --onnx=/home/craner/Documents/remote_cockpit_cpu_exit_20250911/ai_detect/tensorrt/yolo12x-v1.4-nov-300.onnx --saveEngine=/home/craner/Documents/remote_cockpit_cpu_exit_20250911/ai_detect/tensorrt/yolo12x-v1.4-nov-300.engine --fp16

//yolo11m-v0.22-aug-300.pt -> yolo11m-v0.22-aug-300.onnx -> yolo11m-v0.22-aug-300.engine
trtyolo export -w /home/craner/Documents/remote_cockpit_cpu_exit_20250911/ai_detect/tensorrt/yolo11m-v0.22-aug-300.pt -v yolo11 -o /home/craner/Documents/remote_cockpit_cpu_exit_20250911/ai_detect/tensorrt/ -b 1 -s --iou_thres=0.3 --conf_thres=0.3
/usr/src/tensorrt/bin/trtexec --onnx=/home/craner/Documents/remote_cockpit_cpu_exit_20250911/ai_detect/tensorrt/yolo11m-v0.22-aug-300.onnx --saveEngine=/home/craner/Documents/remote_cockpit_cpu_exit_20250911/ai_detect/tensorrt/yolo11m-v0.22-aug-300.engine --fp16 --staticPlugins=/home/craner/Documents/remote_cockpit_cpu_exit_20250911/ai_detect/lib/TensorRT-YOLO/lib/plugin/libcustom_plugins.so --setPluginsToSerialize=/home/craner/Documents/remote_cockpit_cpu_exit_20250911/ai_detect/lib/TensorRT-YOLO/lib/plugin/libcustom_plugins.so
